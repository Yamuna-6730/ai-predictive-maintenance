# AI Predictive Maintenance

## ğŸ“ Project Overview
Unexpected failures in energy infrastructure components like **turbines, transformers, and solar panels** lead to **loss of energy and high maintenance costs**.  
This project applies **AI and Machine Learning** techniques to predict **Remaining Useful Life (RUL)** of engines, helping to schedule **predictive maintenance** before failures occur.  

**Problem Statement:**  
- Predict how many operational cycles remain before an engine fails.  
- The data is multivariate time series from multiple engines (fleet data).  
- Each engine starts with unknown initial wear; faults develop over time.  
- Training data runs engines until failure; test data stops before failure.  

**Proposed Solution:**  
- Train ML models (baseline and deep learning) on sensor and operational data.  
- Use time-series modeling to predict RUL for each engine.  
- Output alerts like: â€œEngine X likely to fail in Y cyclesâ€.  
- Helps reduce downtime and maintenance costs.

---

This project uses the **CMAPSS Turbofan Engine Degradation Simulation Dataset** for building machine learning models to predict the **Remaining Useful Life (RUL)** of engines.  
The dataset consists of four subsets: **FD001, FD002, FD003, FD004**.

---

## ğŸ“‚ Folder Structure
```

 ai_predictive_maintenance/
â”œâ”€â”€ data/ 
â”‚ â”œâ”€â”€ raw/ # Original CMAPSS dataset files (train, test, RUL)
â”‚ â””â”€â”€ processed/ # Cleaned CSVs with RUL column added
â”‚
â”œâ”€â”€ notebooks/ 
â”‚ â”œâ”€â”€ 01_data_preprocessing.ipynb #  Load, clean, RUL, EDA
â”‚ â”œâ”€â”€ 02_baseline_models.ipynb #  ML baseline models (LGBM, XGBoost, Random forest)
â”‚ â”œâ”€â”€ random_forest_pipeline.ipynb #  Random forest model
â”‚ â”œâ”€â”€ deep_learning_comparison.ipynb #  LSTM/TCN models
â”‚ â”œâ”€â”€ 04_dashboard_and_outputs.ipynb # Dashboard & visualization
â”‚
â”œâ”€â”€ utils/ 
â”‚ â”œâ”€â”€ data_pipeline.py # Functions to load & clean data
â”‚ â”œâ”€â”€ feature_engineering.py # Feature extraction functions
â”‚ â””â”€â”€ visualization.py # Plotting utilities
â”‚
â”œâ”€â”€ outputs/ 
â”‚ â”œâ”€â”€ models/ # Trained models (.pkl, .pt)
â”‚ â””â”€â”€ figures/ # Plots and charts
â”‚
â””â”€â”€ README.md # Project documentation

```

---


---

## ğŸ“Š Work Done So Far

âœ”ï¸ **Data Preprocessing & Feature Engineering**
- Loaded all **FD001â€“FD004** CMAPSS datasets.  
- Added **Remaining Useful Life (RUL)** for each unit.  
- Created **binary near-failure label** (`1 if RUL â‰¤ 30 else 0`).  
- Saved clean processed data for modeling.  

âœ”ï¸ **Exploratory Data Analysis**
- Visualized RUL distributions.  
- Plotted sample sensor signals to observe degradation patterns.  

âœ”ï¸ **Baseline ML Models**
- Implemented and compared **Random Forest, XGBoost, and LightGBM**.  
- Reason: These **tree-based models** are strong baselines for tabular sensor data.  

âœ”ï¸ **Deep Learning Models**
- Implemented **LSTM** (sequence learning) and **TCN** (temporal convolutions).  
- Reason: To test if **temporal dependencies** improve prediction accuracy compared to ML baselines.  

âœ”ï¸ **Model Comparison & Selection**
- Evaluated models on **Accuracy, Precision, Recall, and F1 score**.  
- Random Forest consistently provided **best balance of metrics** across datasets.  

---

## ğŸ” Why Compare Multiple Models?

- **Random Forest** â†’ Robust, interpretable, less overfitting.  
- **XGBoost** â†’ Popular boosting method, often state-of-the-art on tabular data.  
- **LightGBM** â†’ Faster boosting, optimized for large-scale datasets.  
- **LSTM / TCN** â†’ Capture sequential dependencies in sensor readings.  

Comparing both **ML baselines and DL models** ensures we donâ€™t miss potential improvements.

---

## ğŸ† Model Selection

After evaluating on **FD001â€“FD004**, Random Forest emerged as the **best overall model**.  
Below is a simplified comparison summary:

| Model          | Accuracy | Precision | Recall | F1 Score | Notes |
|----------------|----------|-----------|--------|----------|-------|
| **Random Forest** | âœ… Highest & stable | âœ… High | âœ… Balanced | âœ… Best overall | **Selected** |
| XGBoost        | High     | High      | Slightly lower | Good | Close, but less consistent |
| LightGBM       | High     | Moderate  | Moderate | Good | Similar to XGBoost |
| LSTM           | Moderate | Good      | Lower   | Lower | Slower, heavy training |
| TCN            | Moderate | Good      | Lower   | Lower | Similar to LSTM |

ğŸ‘‰ **Final Choice:** **Random Forest Classifier**  
- Reliable performance across all datasets.  
- Computationally efficient and interpretable.  
- Outperformed or matched deep learning models in this case.  

---

## Final Steps
- Extend from **classification** to **regression RUL prediction**.  
- Hyperparameter optimization for Random Forest.  
- Build an **interactive dashboard** to monitor engine health.  
- Deploy trained model in an **end-to-end pipeline**.  

---

## ğŸ‘¨â€ğŸ’» Author
**Yamuna L**  
Engineering Student specializing in Data Science  
(Work done as part of AI Predictive Maintenance project challenge for Edunet AICTE shell Internship)


